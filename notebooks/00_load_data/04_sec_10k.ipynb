{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\"> **Donwload SEC 10-K Fillings** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pprint\n",
    "\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../nb_config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from src import utils\n",
    "from src.load_data import load_sec10k, io_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = utils.read_conf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOC_TYPE = '10-K'\n",
    "newest_pricing_data = '2018-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPATH = os.path.join(io_utils.raw_path, 'sec_10k', '')\n",
    "OUTFILE1 = 'metadata.pkl'\n",
    "OUTFILE2 = 'sec_10k.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get 10ks\n",
    "We'll be running NLP analysis on 10-k documents. To do that, we first need to download the documents. For this project, we'll download 10-ks for a few companies. To lookup documents for these companies, we'll use their CIK. If you would like to run this against other stocks, we've provided the dict `additional_cik` for more stocks. However, the more stocks you try, the long it will take to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AMZN': '0001018724',\n",
       " 'BMY': '0000014272',\n",
       " 'CNP': '0001130310',\n",
       " 'CVX': '0000093410',\n",
       " 'FL': '0000850209',\n",
       " 'FRT': '0000034903',\n",
       " 'HON': '0000773840'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_sec10k.cik_lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of 10-ks urls\n",
    "The SEC has a limit on the number of calls that can be made to the website per second. The `SecAPI` class, will cache data from the SEC and prevent you from going over the limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_api = load_sec10k.SecAPI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the class constructed, let's pull a list of filled 10-ks from the SEC for each company."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pull the list using the `get_sec_data` function, then display some of the results. For displaying some of the data, we'll use Amazon as an example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_data = {}\n",
    "sec_dates = {}\n",
    "for ticker, cik in load_sec10k.cik_lookup.items():\n",
    "    sec_data[ticker] = load_sec10k.get_sec_data(sec_api=sec_api, cik=cik, newest_pricing_data=newest_pricing_data, doc_type='10-K')\n",
    "    sec_dates[ticker] = [x[2] for x in sec_data[ticker]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2017-02-10',\n",
       " '2016-01-29',\n",
       " '2015-01-30',\n",
       " '2014-01-31',\n",
       " '2013-01-30',\n",
       " '2012-02-01',\n",
       " '2011-02-28',\n",
       " '2011-01-28',\n",
       " '2010-01-29',\n",
       " '2009-01-30',\n",
       " '2008-02-11',\n",
       " '2007-02-16',\n",
       " '2006-02-17',\n",
       " '2005-03-11',\n",
       " '2004-02-25',\n",
       " '2003-02-19',\n",
       " '2002-01-24',\n",
       " '2001-03-23',\n",
       " '2000-09-08',\n",
       " '2000-03-29',\n",
       " '1999-03-05',\n",
       " '1998-03-30']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_ticker = 'AMZN'\n",
    "sec_dates[example_ticker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('https://www.sec.gov/Archives/edgar/data/1018724/000101872417000011/0001018724-17-000011-index.htm',\n",
      "  '10-K',\n",
      "  '2017-02-10'),\n",
      " ('https://www.sec.gov/Archives/edgar/data/1018724/000101872416000172/0001018724-16-000172-index.htm',\n",
      "  '10-K',\n",
      "  '2016-01-29'),\n",
      " ('https://www.sec.gov/Archives/edgar/data/1018724/000101872415000006/0001018724-15-000006-index.htm',\n",
      "  '10-K',\n",
      "  '2015-01-30'),\n",
      " ('https://www.sec.gov/Archives/edgar/data/1018724/000101872414000006/0001018724-14-000006-index.htm',\n",
      "  '10-K',\n",
      "  '2014-01-31'),\n",
      " ('https://www.sec.gov/Archives/edgar/data/1018724/000119312513028520/0001193125-13-028520-index.htm',\n",
      "  '10-K',\n",
      "  '2013-01-30')]\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(sec_data[example_ticker][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download 10-ks\n",
    "As you see, this is a list of urls. These urls point to a file that contains metadata related to each filling. Since we don't care about the metadata, we'll pull the filling by replacing the url with the filling url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading AMZN Fillings: 100%|██████████| 22/22 [00:04<00:00,  4.62filling/s]\n",
      "Downloading BMY Fillings: 100%|██████████| 27/27 [00:06<00:00,  4.08filling/s]\n",
      "Downloading CNP Fillings: 100%|██████████| 19/19 [00:04<00:00,  4.27filling/s]\n",
      "Downloading CVX Fillings: 100%|██████████| 25/25 [00:06<00:00,  3.64filling/s]\n",
      "Downloading FL Fillings: 100%|██████████| 22/22 [00:04<00:00,  4.55filling/s]\n",
      "Downloading FRT Fillings: 100%|██████████| 29/29 [00:08<00:00,  3.44filling/s]\n",
      "Downloading HON Fillings: 100%|██████████| 25/25 [00:06<00:00,  3.59filling/s]\n"
     ]
    }
   ],
   "source": [
    "raw_fillings_by_ticker = {}\n",
    "\n",
    "for ticker, data in sec_data.items():\n",
    "    raw_fillings_by_ticker[ticker] = {}\n",
    "    for index_url, file_type, file_date in tqdm(data, desc='Downloading {} Fillings'.format(ticker), unit='filling'):\n",
    "        if (file_type == DOC_TYPE):\n",
    "            file_url = index_url.replace('-index.htm', '.txt').replace('.txtl', '.txt')            \n",
    "            \n",
    "            raw_fillings_by_ticker[ticker][file_date] = sec_api.get(file_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Document:\n",
      "\n",
      "<SEC-DOCUMENT>0001018724-17-000011.txt : 20170210\n",
      "<SEC-HEADER>0001018724-17-000011.hdr.sgml : 20170210\n",
      "<ACCEPTANCE-DATETIME>20170209175636\n",
      "ACCESSION NUMBER:\t\t0001018724-17-000011\n",
      "CONFORMED SUBMISSION TYPE:\t10-K\n",
      "PUBLIC DOCUMENT COUNT:\t\t92\n",
      "CONFORMED PERIOD OF REPORT:\t20161231\n",
      "FILED AS OF DATE:\t\t20170210\n",
      "DATE AS OF CHANGE:\t\t20170209\n",
      "\n",
      "FILER:\n",
      "\n",
      "\tCOMPANY DATA:\t\n",
      "\t\tCOMPANY CONFORMED NAME:\t\t\tAMAZON COM INC\n",
      "\t\tCENTRAL INDEX KEY:\t\t\t0001018724\n",
      "\t\tSTANDARD INDUSTRIAL CLASSIFICATION:\tRETAIL-CATALOG & MAIL-ORDER HOUSES [5961]\n",
      "\t\tIRS NUMBER:\t\t\t\t911646860\n",
      "\t\tSTATE OF INCORPORATION:\t\t\tDE\n",
      "\t\tFISCAL YEAR END:\t\t\t1231\n",
      "\n",
      "\tFILING VALUES:\n",
      "\t\tFORM TYPE:\t\t10-K\n",
      "\t\tSEC ACT:\t\t1934 Act\n",
      "\t\tSEC FILE NUMBER:\t000-22513\n",
      "\t\tFILM NUMBER:\t\t17588807\n",
      "\n",
      "\tBUSINESS ADDRESS:\t\n",
      "\t\tSTREET 1:\t\t410 TERRY AVENUE NORTH\n",
      "\t\tCITY:\t\t\tSEATTLE\n",
      "\t\tSTATE:\t\t\tWA\n",
      "\t\tZIP:\t\t\t98109\n",
      "\t\tBUSINESS PHONE:\t\t2062661000\n",
      "\n",
      "\tMAIL ADDRESS:\t\n",
      "\t\tSTREET 1:\t\t410 TERRY AVENUE NORTH\n",
      "\t\tCITY:\t\t\tSEATTLE\n",
      "\t\tSTATE:\t\t\tWA\n",
      "\t\tZIP:\t\t\t98109\n",
      "</SEC-HEADER>\n",
      "<DOCUMENT>\n",
      "<TYPE>10-K\n",
      "<SEQUENCE>1\n",
      "<FILENAME...\n"
     ]
    }
   ],
   "source": [
    "print('Example Document:\\n\\n{}...'.format(next(iter(raw_fillings_by_ticker[example_ticker].values()))[:1000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Documents\n",
    "Each filling is broken into several associated documents, sectioned off in the fillings with the tags:\n",
    "      <DOCUMENT> </DOCUMENT> There's no overlap with these documents, so each `</DOCUMENT>` tag should come after the `<DOCUMENT>` with no `<DOCUMENT>` tag in between.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting Documents from AMZN Fillings: 100%|██████████| 17/17 [00:00<00:00, 73.78filling/s]\n",
      "Getting Documents from BMY Fillings: 100%|██████████| 23/23 [00:00<00:00, 42.79filling/s]\n",
      "Getting Documents from CNP Fillings: 100%|██████████| 15/15 [00:00<00:00, 44.10filling/s]\n",
      "Getting Documents from CVX Fillings: 100%|██████████| 21/21 [00:00<00:00, 43.50filling/s]\n",
      "Getting Documents from FL Fillings: 100%|██████████| 16/16 [00:00<00:00, 71.92filling/s]\n",
      "Getting Documents from FRT Fillings: 100%|██████████| 19/19 [00:00<00:00, 67.20filling/s]\n",
      "Getting Documents from HON Fillings: 100%|██████████| 20/20 [00:00<00:00, 53.62filling/s]\n"
     ]
    }
   ],
   "source": [
    "filling_documents_by_ticker = {}\n",
    "\n",
    "for ticker, raw_fillings in raw_fillings_by_ticker.items():\n",
    "    filling_documents_by_ticker[ticker] = {}\n",
    "    for file_date, filling in tqdm(raw_fillings.items(), desc='Getting Documents from {} Fillings'.format(ticker), unit='filling'):\n",
    "        filling_documents_by_ticker[ticker][file_date] = load_sec10k.get_documents(filling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0 Filed on 2017-02-10:\n",
      "\n",
      "<TYPE>10-K\n",
      "<SEQUENCE>1\n",
      "<FILENAME>amzn-20161231x10k.htm\n",
      "<DESCRIPTION>FORM 10-K\n",
      "<TEXT>\n",
      "<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n",
      "<html>\n",
      "\t<he...\n",
      "\n",
      "Document 1 Filed on 2017-02-10:\n",
      "\n",
      "<TYPE>EX-12.1\n",
      "<SEQUENCE>2\n",
      "<FILENAME>amzn-20161231xex121.htm\n",
      "<DESCRIPTION>COMPUTATION OF RATIO OF EARNINGS TO FIXED CHARGES\n",
      "<TEXT>\n",
      "<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http:...\n",
      "\n",
      "Document 2 Filed on 2017-02-10:\n",
      "\n",
      "<TYPE>EX-21.1\n",
      "<SEQUENCE>3\n",
      "<FILENAME>amzn-20161231xex211.htm\n",
      "<DESCRIPTION>LIST OF SIGNIFICANT SUBSIDIARIES\n",
      "<TEXT>\n",
      "<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/h...\n"
     ]
    }
   ],
   "source": [
    "print('\\n\\n'.join([\n",
    "    'Document {} Filed on {}:\\n{}...'.format(doc_i, file_date, doc[:200])\n",
    "    for file_date, docs in filling_documents_by_ticker[example_ticker].items()\n",
    "    for doc_i, doc in enumerate(docs)][:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Document Types\n",
    "Now that we have all the documents, we want to find the 10-k form in this 10-k filing. Implement the `get_document_type` function to return the type of document given. The document type is located on a line with the `<TYPE>` tag. For example, a form of type \"TEST\" would have the line `<TYPE>TEST`. Make sure to return the type as lowercase, so this example would be returned as \"test\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `get_document_type` function, we'll filter out all non 10-k documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_ks_by_ticker = {}\n",
    "\n",
    "for ticker, filling_documents in filling_documents_by_ticker.items():\n",
    "    ten_ks_by_ticker[ticker] = []\n",
    "    for file_date, documents in filling_documents.items():\n",
    "        for document in documents:\n",
    "            if load_sec10k.get_document_type(document) == DOC_TYPE:\n",
    "                ten_ks_by_ticker[ticker].append({\n",
    "                    'cik': load_sec10k.cik_lookup[ticker],\n",
    "                    'file': document,\n",
    "                    'file_date': file_date})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    cik: '0001018724'\n",
      "    file: '\\n<TYPE>10-K\\n<SEQUENCE>1\\n<FILENAME>amzn-2016123...\n",
      "    file_date: '2017-02-10'},\n",
      "  {\n",
      "    cik: '0001018724'\n",
      "    file: '\\n<TYPE>10-K\\n<SEQUENCE>1\\n<FILENAME>amzn-2015123...\n",
      "    file_date: '2016-01-29'},\n",
      "  {\n",
      "    cik: '0001018724'\n",
      "    file: '\\n<TYPE>10-K\\n<SEQUENCE>1\\n<FILENAME>amzn-2014123...\n",
      "    file_date: '2015-01-30'},\n",
      "  {\n",
      "    cik: '0001018724'\n",
      "    file: '\\n<TYPE>10-K\\n<SEQUENCE>1\\n<FILENAME>amzn-2013123...\n",
      "    file_date: '2014-01-31'},\n",
      "  {\n",
      "    cik: '0001018724'\n",
      "    file: '\\n<TYPE>10-K\\n<SEQUENCE>1\\n<FILENAME>d445434d10k....\n",
      "    file_date: '2013-01-30'},\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "load_sec10k.print_ten_k_data(ten_ks_by_ticker[example_ticker][:5], ['cik', 'file', 'file_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2013-01-30'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_ks_by_ticker[example_ticker][4]['file_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<TYPE>10-K\\n<SEQUENCE>1\\n<FILENAME>d445434d10k.htm\\n<DESCRIPTION>FORM 10-K\\n<TEXT>\\n<HTML><HEAD>\\n<TITLE>Form 10-K</TITLE>\\n</HEAD>\\n <BODY BGCOLOR=\"WHITE\">\\n<h5 align=\"left\"><a href=\"#toc\">Table of Contents</a></h5>\\n\\n <P STYLE=\"line-height:0px;margin-top:0px;margin-bottom:0px;border-bottom:0.5pt solid #000000\">&nbsp;</P>\\n<P STYLE=\"line-height:3px;margin-top:0px;margin-bottom:2px;border-bottom:0.5pt solid #000000\">&nbsp;</P> <P STYLE=\"margin-top:4px;margin-bottom:0px\" ALIGN=\"center\"><FONT STYLE=\"font-family:Times New Roman\" SIZE=\"5\"><B>UNITED STATES </B></FONT></P>\\n<P STYLE=\"margin-top:0px;margin-bottom:0px\" ALIGN=\"center\"><FONT STYLE=\"font-family:Times New Roman\" SIZE=\"5\"><B>SECURITIES AND EXCHANGE COMMISSION </B></FONT></P> <P STYLE=\"margin-top:0px;margin-bottom:0px\" ALIGN=\"center\"><FONT\\nSTYLE=\"font-family:Times New Roman\" SIZE=\"3\"><B>Washington, D.C. 20549 </B></FONT></P> <P STYLE=\"font-size:6px;margin-top:0px;margin-bottom:0px\">&nbsp;</P><center>\\n<P STYLE=\"line-height:6px;margin-top:0px;ma'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_ks_by_ticker[example_ticker][4]['file'][:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Raw 10Ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {'newest_pricing_data': '2018-01-01',\n",
    "           'tickers': load_sec10k.cik_lookup}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(OUTPATH + OUTFILE1, 'wb') as file:\n",
    "    pickle.dump(metadata, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(OUTPATH + OUTFILE2, 'wb') as file:\n",
    "    pickle.dump(ten_ks_by_ticker, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
