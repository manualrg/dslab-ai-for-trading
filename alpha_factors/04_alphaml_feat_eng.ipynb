{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\"> **Feature Engineering and Targets** </font>\n",
    "* Alpha Factors\n",
    "* Universal Quant Features\n",
    "* Time-based features\n",
    "* Sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "# Retrieve parameters from configuration file\n",
    "with open(\"../conf.yml\", \"r\") as ymlfile:\n",
    "    cfg = yaml.load(ymlfile)\n",
    "\n",
    "BUNDLE_FOLDER = cfg['quantopian']['dataset3']['bundle_folder']\n",
    "BUNDLE_NAME = cfg['quantopian']['dataset3']['bundle_name']\n",
    "SECTOR_FOLDER = cfg['quantopian']['dataset3']['sector_folder']\n",
    "SECTOR_DATA = cfg['quantopian']['dataset3']['sector_data']\n",
    "SECTOR_NAMES = cfg['quantopian']['dataset3']['sector_names']\n",
    "\n",
    "# Specify the bundle path\n",
    "bundle_path = os.path.join(os.getcwd(), '..', 'data', BUNDLE_FOLDER)\n",
    "sector_path = os.path.join(os.getcwd(), '..', 'data', SECTOR_FOLDER, SECTOR_DATA)\n",
    "sector_file = os.path.join(os.getcwd(), '..', 'data', SECTOR_FOLDER, SECTOR_NAMES)\n",
    "os.path.isdir(bundle_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAU = cfg['models']['alpha_ml']['tau']\n",
    "target_col = cfg['models']['alpha_ml']['target_col']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from mle_quant_utils import quant_helper, quant_factors, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipline.data import bundles\n",
    "from zipline.utils.calendars import get_calendar\n",
    "from zipline.pipeline.factors import AnnualizedVolatility, AverageDollarVolume, Returns, SimpleMovingAverage, RSI, MACDSignal\n",
    "from zipline.pipeline.factors.technical import BollingerBands\n",
    "from zipline.pipeline import Pipeline\n",
    "from zipline.data.data_portal import DataPortal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import alphalens as al"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Registered\n"
     ]
    }
   ],
   "source": [
    "# Data Bundle\n",
    "os.environ['ZIPLINE_ROOT'] = bundle_path\n",
    "ingest_func = bundles.csvdir.csvdir_equities(['daily'], BUNDLE_NAME)\n",
    "bundles.register(BUNDLE_NAME, ingest_func)\n",
    "print('Data Registered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Universe ADV window: 120 and top threshold: 500\n"
     ]
    }
   ],
   "source": [
    "adv_win = cfg['models']['universe']['window']\n",
    "adv_top = cfg['models']['universe']['adv_top']\n",
    "print('Universe ADV window: {} and top threshold: {}'.format(adv_win, adv_top))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Universe start: 2016-01-05 00:00:00+00:00 and end: 2013-01-03 00:00:00+00:00 dates\n"
     ]
    }
   ],
   "source": [
    "universe_end_date =  pd.Timestamp( cfg['models']['universe']['start'], tz='UTC') # pd.Timestamp('2016-01-05', tz='UTC')\n",
    "factor_start_date =  pd.Timestamp( cfg['models']['universe']['end'], tz='UTC')  # universe_end_date - pd.DateOffset(years=3, days=2)\n",
    "print('Universe start: {} and end: {} dates'.format(universe_end_date, factor_start_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe = AverageDollarVolume(window_length=adv_win).top(adv_top) \n",
    "trading_calendar = get_calendar('NYSE') \n",
    "bundle_data = bundles.load(BUNDLE_NAME)\n",
    "engine =  quant_helper.build_pipeline_engine(bundle_data, trading_calendar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(screen=universe)\n",
    "pipeline_target = Pipeline(screen=universe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_portal = DataPortal(\n",
    "    bundle_data.asset_finder,\n",
    "    trading_calendar=trading_calendar,\n",
    "    first_trading_day=bundle_data.equity_daily_bar_reader.first_trading_day,\n",
    "    equity_minute_reader=None,\n",
    "    equity_daily_reader=bundle_data.equity_daily_bar_reader,\n",
    "    adjustment_reader=bundle_data.adjustment_reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encode Sectors\n",
    "For the model to better understand the sector data, we'll one hot encode this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector = quant_helper.get_sectors(sector_path)\n",
    "sector_lookup = pd.read_csv(sector_file, index_col='Sector_i')['Sector']\n",
    "sector_lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpha Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.add(\n",
    "    quant_factors.momentum_smoothed(252, 5, universe, sector),\n",
    "    'Momentum_1YR_Smoothed')\n",
    "pipeline.add(\n",
    "    quant_factors.mean_reversion_sector_neutral_smoothed(5, universe, sector),\n",
    "    'Mean_Reversion_Sector_Neutral_Smoothed')\n",
    "pipeline.add(\n",
    "    quant_factors.overnight_sentiment_smoothed(2, 5, universe),\n",
    "    'Overnight_Sentiment_Smoothed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.add(AnnualizedVolatility(window_length=20, mask=universe).rank().zscore(), 'volatility_20d')\n",
    "pipeline.add(AnnualizedVolatility(window_length=120, mask=universe).rank().zscore(), 'volatility_120d')\n",
    "pipeline.add(AverageDollarVolume(window_length=20, mask=universe).rank().zscore(), 'adv_20d')\n",
    "pipeline.add(AverageDollarVolume(window_length=120, mask=universe).rank().zscore(), 'adv_120d')\n",
    "pipeline.add(sector, 'sector_code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regime Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.add(SimpleMovingAverage(inputs=[quant_factors.MarketDispersion(mask=universe)], window_length=20), 'dispersion_20d')\n",
    "pipeline.add(SimpleMovingAverage(inputs=[quant_factors.MarketDispersion(mask=universe)], window_length=120), 'dispersion_120d')\n",
    "pipeline.add(quant_factors.MarketVolatility(window_length=20), 'market_vol_20d')\n",
    "pipeline.add(quant_factors.MarketVolatility(window_length=120), 'market_vol_120d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_factors = engine.run_pipeline(pipeline, factor_start_date, universe_end_date)\n",
    "all_factors.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_factors['is_January'] = all_factors.index.get_level_values(0).month == 1\n",
    "all_factors['is_December'] = all_factors.index.get_level_values(0).month == 12\n",
    "all_factors['weekday'] = all_factors.index.get_level_values(0).weekday\n",
    "all_factors['quarter'] = all_factors.index.get_level_values(0).quarter\n",
    "all_factors['qtr_yr'] = all_factors.quarter.astype('str') + '_' + all_factors.index.get_level_values(0).year.astype('str')\n",
    "all_factors['month_end'] = all_factors.index.get_level_values(0).isin(pd.date_range(start=factor_start_date, end=universe_end_date, freq='BM'))\n",
    "all_factors['month_start'] = all_factors.index.get_level_values(0).isin(pd.date_range(start=factor_start_date, end=universe_end_date, freq='BMS'))\n",
    "all_factors['qtr_end'] = all_factors.index.get_level_values(0).isin(pd.date_range(start=factor_start_date, end=universe_end_date, freq='BQ'))\n",
    "all_factors['qtr_start'] = all_factors.index.get_level_values(0).isin(pd.date_range(start=factor_start_date, end=universe_end_date, freq='BQS'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OHE Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_factors['sector_code'].value_counts(normalize=True).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors_ohe_df = pd.get_dummies(all_factors['sector_code'], prefix='sector_code')\n",
    "sectors_ohe_cols = sectors_ohe_df.columns.tolist()\n",
    "sectors_ohe_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtr_ohe_df = pd.get_dummies(all_factors['quarter'], prefix='qtr')\n",
    "qtr_ohe_cols = qtr_ohe_df.columns.tolist()\n",
    "qtr_ohe_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_ohe_df = pd.get_dummies(all_factors['weekday'], prefix='weekday')\n",
    "weekday_ohe_cols = weekday_ohe_df.columns.tolist()\n",
    "weekday_ohe_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_factors[sectors_ohe_cols] = sectors_ohe_df\n",
    "all_factors[qtr_ohe_cols] = qtr_ohe_df\n",
    "all_factors[weekday_ohe_cols] = weekday_ohe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Mean_Reversion_Sector_Neutral_Smoothed',\n",
    " 'Momentum_1YR_Smoothed',\n",
    " 'Overnight_Sentiment_Smoothed',\n",
    " 'adv_120d',\n",
    " 'adv_20d',\n",
    " 'dispersion_120d',\n",
    " 'dispersion_20d',\n",
    " 'market_vol_120d',\n",
    " 'market_vol_20d',\n",
    " 'volatility_120d',\n",
    " 'volatility_20d',\n",
    " 'is_January',\n",
    " 'is_December',\n",
    " 'month_start',\n",
    " 'month_end',\n",
    " 'qtr_end',\n",
    " 'qtr_start'] + sectors_ohe_cols + qtr_ohe_cols + weekday_ohe_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_factors = all_factors[features].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_d_raw = 'return_{}d_raw'.format(TAU)\n",
    "return_d = 'return_{}d'.format(TAU)\n",
    "return_d_5p = 'return_{}d_5p'.format(TAU)\n",
    "return_d_25p = 'return_{}d_25p'.format(TAU)\n",
    "\n",
    "pipeline_target.add(Returns(window_length=TAU, mask=universe), return_d_raw)\n",
    "pipeline_target.add(Returns(window_length=TAU, mask=universe).quantiles(2), return_d)\n",
    "pipeline_target.add(Returns(window_length=TAU, mask=universe).quantiles(5), return_d_5p)\n",
    "pipeline_target.add(Returns(window_length=TAU, mask=universe).quantiles(25), return_d_25p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_df = engine.run_pipeline(pipeline_target, factor_start_date, universe_end_date)\n",
    "targets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_df.dropna().groupby(return_d)[return_d_raw].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=targets_df[return_d],\n",
    "            columns=targets_df[return_d_raw]>0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing two quantiles yields a boundary that does not respect zero, therefore, same few points at target 0 are positive returns and viceversa. Any even number bucketization should use zero as a threshold, on the other hand, odd number quantiles may left a band around zero is variable distribution behaves properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_d_raw_is_positive = 'return_{}d_is_positive'.format(TAU)\n",
    "targets_df[return_d_raw_is_positive] = targets_df[return_d_raw].apply(utils.safe_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_df[target_col] = targets_df.groupby(level=1)[return_d_raw_is_positive].shift(-TAU)\n",
    "targets_df[[return_d, target_col]].reset_index().sort_values(['level_1', 'level_0']).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_rows = targets_df.index.get_level_values(0).unique()[:-TAU]\n",
    "select_rows[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_df = targets_df.loc[(select_rows, slice(None)), :]\n",
    "all_factors = all_factors.loc[(select_rows, slice(None)), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_factors_isna = all_factors.isna().sum(axis=1)\n",
    "all_factors = all_factors.interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of rows with any missing value: ', len(all_factors_isna[all_factors_isna>0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset conformance checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(targets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(targets_df[target_col].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_factors.dropna())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
