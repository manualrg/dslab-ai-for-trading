{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering and Targets\n",
    "\n",
    "* Alpha Factors\n",
    "* Universal Quant Features\n",
    "* Time-based features\n",
    "* Sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "# Retrieve parameters from configuration file\n",
    "with open(\"../conf.yml\", \"r\") as ymlfile:\n",
    "    cfg = yaml.load(ymlfile)\n",
    "\n",
    "BUNDLE_FOLDER = cfg['quantopian']['dataset3']['bundle_folder']\n",
    "BUNDLE_NAME = cfg['quantopian']['dataset3']['bundle_name']\n",
    "SECTOR_FOLDER = cfg['quantopian']['dataset3']['sector_folder']\n",
    "SECTOR_DATA = cfg['quantopian']['dataset3']['sector_data']\n",
    "SECTOR_NAMES = cfg['quantopian']['dataset3']['sector_names']\n",
    "\n",
    "# Specify the bundle path\n",
    "bundle_path = os.path.join(os.getcwd(), '..', 'data', BUNDLE_FOLDER)\n",
    "sector_path = os.path.join(os.getcwd(), '..', 'data', SECTOR_FOLDER, SECTOR_DATA)\n",
    "sector_file = os.path.join(os.getcwd(), '..', 'data', SECTOR_FOLDER, SECTOR_NAMES)\n",
    "os.path.isdir(bundle_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import quant_helper, quant_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipline.data import bundles\n",
    "from zipline.utils.calendars import get_calendar\n",
    "from zipline.pipeline.factors import AnnualizedVolatility, AverageDollarVolume, Returns, SimpleMovingAverage, RSI, MACDSignal\n",
    "from zipline.pipeline.factors.technical import BollingerBands\n",
    "from zipline.pipeline import Pipeline\n",
    "from zipline.data.data_portal import DataPortal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import alphalens as al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\quant-ai4trading\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Overwriting bundle with name 'eod-quotemedia'\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Data Bundle\n",
    "os.environ['ZIPLINE_ROOT'] = bundle_path\n",
    "ingest_func = bundles.csvdir.csvdir_equities(['daily'], BUNDLE_NAME)\n",
    "bundles.register(BUNDLE_NAME, ingest_func)\n",
    "print('Data Registered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe = AverageDollarVolume(window_length=120).top(500) \n",
    "trading_calendar = get_calendar('NYSE') \n",
    "bundle_data = bundles.load(BUNDLE_NAME)\n",
    "engine =  quant_helper.build_pipeline_engine(bundle_data, trading_calendar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe_end_date = pd.Timestamp('2016-01-05', tz='UTC')\n",
    "factor_start_date = universe_end_date - pd.DateOffset(years=3, days=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(screen=universe)\n",
    "pipeline_target = Pipeline(screen=universe)\n",
    "tech_pl = Pipeline(screen=universe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encode Sectors\n",
    "For the model to better understand the sector data, we'll one hot encode this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sector_i\n",
       "0                 Healthcare\n",
       "1                 Technology\n",
       "2         Consumer Defensive\n",
       "3                Industrials\n",
       "4                  Utilities\n",
       "5         Financial Services\n",
       "6                Real Estate\n",
       "7     Communication Services\n",
       "8          Consumer Cyclical\n",
       "9                     Energy\n",
       "10           Basic Materials\n",
       "Name: Sector, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sector = quant_helper.get_sectors(sector_path)\n",
    "sector_lookup = pd.read_csv(sector_file, index_col='Sector_i')['Sector']\n",
    "sector_lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpha Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.add(\n",
    "    quant_factors.momentum_1yr(252, universe, sector),\n",
    "    'Momentum_1YR')\n",
    "pipeline.add(\n",
    "    quant_factors.mean_reversion_5day_sector_neutral_smoothed(20, universe, sector),\n",
    "    'Mean_Reversion_Sector_Neutral_Smoothed')\n",
    "pipeline.add(\n",
    "    quant_factors.overnight_sentiment_smoothed(2, 10, universe),\n",
    "    'Overnight_Sentiment_Smoothed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.add(\n",
    "    RSI(window_length=15, mask=universe),\n",
    "    'RSI_15')\n",
    "pipeline.add(\n",
    "    MACDSignal(fast_period=12, slow_period=26, signal_period=9),\n",
    "    'MACD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.add(AnnualizedVolatility(window_length=20, mask=universe).rank().zscore(), 'volatility_20d')\n",
    "pipeline.add(AnnualizedVolatility(window_length=120, mask=universe).rank().zscore(), 'volatility_120d')\n",
    "pipeline.add(AverageDollarVolume(window_length=20, mask=universe).rank().zscore(), 'adv_20d')\n",
    "pipeline.add(AverageDollarVolume(window_length=120, mask=universe).rank().zscore(), 'adv_120d')\n",
    "pipeline.add(sector, 'sector_code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regime Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.add(SimpleMovingAverage(inputs=[quant_factors.MarketDispersion(mask=universe)], window_length=20), 'dispersion_20d')\n",
    "pipeline.add(SimpleMovingAverage(inputs=[quant_factors.MarketDispersion(mask=universe)], window_length=120), 'dispersion_120d')\n",
    "pipeline.add(quant_factors.MarketVolatility(window_length=20), 'market_vol_20d')\n",
    "pipeline.add(quant_factors.MarketVolatility(window_length=120), 'market_vol_120d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 363734 entries, (2013-01-03 00:00:00+00:00, Equity(0 [A])) to (2016-01-05 00:00:00+00:00, Equity(490 [ZTS]))\n",
      "Data columns (total 14 columns):\n",
      "MACD                                      363083 non-null float64\n",
      "Mean_Reversion_Sector_Neutral_Smoothed    360790 non-null float64\n",
      "Momentum_1YR                              357288 non-null float64\n",
      "Overnight_Sentiment_Smoothed              363734 non-null float64\n",
      "RSI_15                                    363711 non-null float64\n",
      "adv_120d                                  363734 non-null float64\n",
      "adv_20d                                   363734 non-null float64\n",
      "dispersion_120d                           363734 non-null float64\n",
      "dispersion_20d                            363734 non-null float64\n",
      "market_vol_120d                           363734 non-null float64\n",
      "market_vol_20d                            363734 non-null float64\n",
      "sector_code                               363734 non-null int64\n",
      "volatility_120d                           363714 non-null float64\n",
      "volatility_20d                            363714 non-null float64\n",
      "dtypes: float64(13), int64(1)\n",
      "memory usage: 40.2+ MB\n"
     ]
    }
   ],
   "source": [
    "all_factors = engine.run_pipeline(pipeline, factor_start_date, universe_end_date)\n",
    "all_factors.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipline.pipeline.data import USEquityPricing\n",
    "\n",
    "class customBB(BollingerBands):\n",
    "\n",
    "    inputs = (USEquityPricing.close,)\n",
    "    outputs = 'lower', 'middle', 'upper', 'ind_upper' ,'ind_lower'\n",
    "    \n",
    "    def compute(self, today, assets, out, close, k):\n",
    "        std = np.nanstd(close, axis=0)\n",
    "        difference = k * std\n",
    "        out.middle = middle = np.nanmean(close, axis=0)\n",
    "        out.upper = middle + difference\n",
    "        out.lower = middle - difference\n",
    "        out.close = close[-1,:]\n",
    "        out.ind_upper = np.where(out.close>out.upper,1,0)\n",
    "        out.ind_lower = np.where(out.close<out.lower,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(59.979418203347045, 63.57166666666667, 67.1639151299863, 0.0, 0.0)],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tech_factors = engine.run_pipeline(tech_pl, factor_start_date, universe_end_date)\n",
    "tech_factors.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(59.979418203347045, 63.57166666666667, 67.1639151299863, 0.0, 0.0)],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tech_factors.head(1)['BB_60d'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_factors['is_January'] = all_factors.index.get_level_values(0).month == 1\n",
    "all_factors['is_December'] = all_factors.index.get_level_values(0).month == 12\n",
    "all_factors['weekday'] = all_factors.index.get_level_values(0).weekday\n",
    "all_factors['quarter'] = all_factors.index.get_level_values(0).quarter\n",
    "all_factors['qtr_yr'] = all_factors.quarter.astype('str') + '_' + all_factors.index.get_level_values(0).year.astype('str')\n",
    "all_factors['month_end'] = all_factors.index.get_level_values(0).isin(pd.date_range(start=factor_start_date, end=universe_end_date, freq='BM'))\n",
    "all_factors['month_start'] = all_factors.index.get_level_values(0).isin(pd.date_range(start=factor_start_date, end=universe_end_date, freq='BMS'))\n",
    "all_factors['qtr_end'] = all_factors.index.get_level_values(0).isin(pd.date_range(start=factor_start_date, end=universe_end_date, freq='BQ'))\n",
    "all_factors['qtr_start'] = all_factors.index.get_level_values(0).isin(pd.date_range(start=factor_start_date, end=universe_end_date, freq='BQS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_columns = []\n",
    "for sector_i, sector_name in sector_lookup.items():\n",
    "    sector_column = 'sector_code_{}'.format(sector_i)\n",
    "    sector_columns.append(sector_column)\n",
    "    all_factors[sector_column] = (all_factors['sector_code'] == sector_i)\n",
    "\n",
    "all_factors[sector_columns].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Mean_Reversion_Sector_Neutral_Smoothed',\n",
    " 'Momentum_1YR',\n",
    " 'Overnight_Sentiment_Smoothed',\n",
    " 'adv_120d',\n",
    " 'adv_20d',\n",
    " 'dispersion_120d',\n",
    " 'dispersion_20d',\n",
    " 'market_vol_120d',\n",
    " 'market_vol_20d',\n",
    " #'sector_code', # removed sector_code\n",
    " 'volatility_120d',\n",
    " 'volatility_20d',\n",
    " 'sector_code_0',\n",
    " 'sector_code_1',\n",
    " 'sector_code_2',\n",
    " 'sector_code_3',\n",
    " 'sector_code_4',\n",
    " 'sector_code_5',\n",
    " 'sector_code_6',\n",
    " 'sector_code_7',\n",
    " 'sector_code_8',\n",
    " 'sector_code_9',\n",
    " 'sector_code_10',\n",
    " 'is_January',\n",
    " 'is_December',\n",
    " 'weekday',\n",
    " 'quarter',\n",
    " 'month_start',\n",
    " 'qtr_end',\n",
    " 'qtr_start']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_target.add(Returns(window_length=5, mask=universe), 'return_5d_raw')\n",
    "pipeline_target.add(Returns(window_length=5, mask=universe).quantiles(2), 'return_5d')\n",
    "pipeline_target.add(Returns(window_length=5, mask=universe).quantiles(5), 'return_5d_p')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_df = engine.run_pipeline(pipeline_target, factor_start_date, universe_end_date)\n",
    "targets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_df['target'] = targets_df.groupby(level=1)['return_5d'].shift(-5)\n",
    "targets_df[['return_5d','target']].reset_index().sort_values(['level_1', 'level_0']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify from prices data\n",
    "ticker = prices_df.columns[0]\n",
    "dates = list(pd.date_range('2014-01-03', '2014-01-07'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_df.loc[(dates, ticker) , 'return_5d_raw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pct_change(tau): (p[t]-p[t-tau])/p[t-tau]\n",
    "#5d returns in quantopian are weekly returns\n",
    "prices_df[ticker].pct_change(4)['2014-01-01':].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current: 2014-01-02\n",
    "# tau=4 2013-12-26\n",
    "(prices_df.loc['2014-01-02', ticker] - prices_df.loc['2013-12-26', ticker])/prices_df.loc['2013-12-26', ticker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(factor_start_date, universe_end_date)\n",
    "targets_df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
